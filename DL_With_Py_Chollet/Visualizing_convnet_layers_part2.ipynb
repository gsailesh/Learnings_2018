{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load a sample image from local.\n",
    "Rescale it to dimensions suited for VGG16 \n",
    "'''\n",
    "\n",
    "image_path = 'data/Misc/female-elephant.jpg'\n",
    "input_image = image.load_img(path=image_path, target_size=(224,224)) \n",
    "\n",
    "X = image.img_to_array(input_image) # converts the input to the dimensions: (224,224,3)\n",
    "X = np.expand_dims(X,axis=0) # adds the batch dimension ; i.e. (1,224,224,3)\n",
    "X = preprocess_input(X) # performs channel-wise colour normalization on the batch of images (X now has batch dimenstion!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape:  (None, 14, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "FINAL_CONV_LAYER = 'block5_conv3'\n",
    "FINAL_CONV_OUTPUT_SHAPE = model.get_layer(FINAL_CONV_LAYER).output_shape\n",
    "\n",
    "print(\"Final output shape: \", FINAL_CONV_OUTPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [[('n02504458', 'African_elephant', 0.8451774), ('n01871265', 'tusker', 0.14580026), ('n02504013', 'Indian_elephant', 0.008667604)]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X)\n",
    "decoded_predictions = decode_predictions(prediction,top=3)\n",
    "\n",
    "print(\"Classes: \", decoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index:  386\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Pick up the index of the most probable class.\n",
    "Here it's teh index corresponding to the class: African_elephant - which has 84.5% probability\n",
    "'''\n",
    "# print(\"Prediction: \", prediction[0])\n",
    "print(\"Class index: \", np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the index info for Gradient CAM (Class Activation Map) based detection.\n",
    "Use the feature map from the output of the last convolution layer in VGG16 - block5_conv3 (FINAL_CONV_LAYER).\n",
    "\n",
    "'''\n",
    "\n",
    "prediction_output = model.output[:,386]\n",
    "final_conv_layer = model.get_layer(FINAL_CONV_LAYER)\n",
    "\n",
    "FINAL_CONV_OUTPUT_SHAPE = FINAL_CONV_OUTPUT_SHAPE[len(FINAL_CONV_OUTPUT_SHAPE)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(14, 14, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient CAM approach calculates the gradient for\n",
    "output feature map of the convolution layer (here, the final_conv_layer)\n",
    "against the predicted class (here, prediction_output).\n",
    "'''\n",
    "\n",
    "# gradients - Tensor of shape same as FINAL_CONV_LAYER\n",
    "gradients = K.gradients(prediction_output, final_conv_layer.output)[0]\n",
    "\n",
    "print(gradients[0])\n",
    "\n",
    "# Tensor of shape (512.) for each channel - each row corresponds to intensity of a channel\n",
    "channel_wise_gradients = K.mean(gradients, axis=(0,1,2))\n",
    "# print(channel_wise_gradients.shape)\n",
    "\n",
    "iterate = K.function([model.input], [channel_wise_gradients, final_conv_layer.output[0]])\n",
    "\n",
    "# Applies the above function to the input image array - X\n",
    "channel_wise_grad_value, final_conv_layer_output_value = iterate([X])\n",
    "\n",
    "# Applies channel-wise intensities (gradient values) onto the corresponding `final_conv_layer_output_value` elements\n",
    "for i in range(FINAL_CONV_OUTPUT_SHAPE):\n",
    "    final_conv_layer_output_value[:,:,i] *= channel_wise_grad_value[i]\n",
    "\n",
    "# Produces a heatmap of shape (14,14) based on mean values of `final_conv_layer_output_value`\n",
    "heatmap = np.mean(final_conv_layer_output_value, axis=-1)\n",
    "\n",
    "# print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbd3729b4a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Normalize the heatmap intensities for visualization purposes.\n",
    "\n",
    "np.maximum() produces element-wise maximum ; either positive or zero\n",
    "Dividing by np.max() produces normalized values within (0,1) for heatmap.\n",
    "'''\n",
    "heatmap = np.maximum(heatmap,0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_image = cv2.imread(image_path)\n",
    "\n",
    "heatmap_resized = cv2.resize(heatmap, (actual_image.shape[1], actual_image.shape[0]))\n",
    "heatmap_resized = np.uint8(255 * heatmap_resized) # Converts to RGB\n",
    "\n",
    "heatmap_resized = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
    "superimposed_image = heatmap_resized * 0.4 + actual_image # 0.4 is the heatmap intensity factor\n",
    "\n",
    "cv2.imwrite('data/Misc/female-elephant_cam.jpg', superimposed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
